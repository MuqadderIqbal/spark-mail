# Data Science for big datasets
* vertical scaling - big iron (graphics)
* horizontal scaling - parallel/distributed computing (graphics)

# Lineage
* Google File System, Google MapReduce papers

# Apache Hadoop
* Open source - Hadoop HDFS, MapReduce

# Apache Hadoop Failure Redundancy
* Failure redundancy - disk

# Apache Spark
* Resilient Distributed Datasets (RDDs)
* Cache in memory

# Apache Spark Failure Redundancy
* Lineage/transformations back to source - recompute

# Cluster Managers

# Getting Faster
* Java Objects - large
* Kryo serialization for data exchange/shuffle operations
* Garbage collection - slow
* Offheap memory storage - DataFrames and Datasets

# Datasets
* Sources, typing

# Partitioning
* original - from source (e.g. HDFS blocks)

# Transformations vs. Actions
* Lazy evaluation

# GUI

# Batch

# Shell

# Streaming

# API

